---
layout: post
title: ceph中PG和PGP的区别（转）
tags:
- ceph
categories: ceph
description: ceph中PG和PGP的区别
---


在ceph官网上对PG做了较为详尽的解释，但是对于PGP的解释较为模糊。本篇文章结合相应的实例来对PG及PGP之间的区别来做一个说明。

<!-- more -->

## 1. 前言
首先来一段关于PG和PGP区别的解释：

>PG = Placement Group
>PGP = Placement Group for Placement purpose
>
>pg_num = number of placement groups mapped to an OSD
>
>When pg_num is increased for any pool, every PG of this pool splits into half, but they all remain mapped to their parent OSD.
>
>Until this time, Ceph does not start rebalancing. Now, when you increase the pgp_num value for the same pool, PGs start to migrate from the parent to some other OSD, and cluster rebalancing starts. This is how PGP plays an important role.
>
>By Karan Singh

以上是来自邮件列表的Karan Singh的PG和PGP的相关解释，他也是Learning Ceph和Ceph Cookbook的作者，以上的解释没有问题，我们来看下具体在集群里面的作用。

## 2. 实践
环境准备，因为是测试环境，我只准备了两台机器，每台机器4个OSD，所以做了一些参数的设置，让数据尽量散列：
<pre>
osd_crush_chooseleaf_type = 0
</pre>

以上为修改的参数，这个是让我的环境故障域为OSD分组的。


1） 创建测试需要的存储池

我们初始情况只创建一个名为testpool，包含6个PG的存储池：
<pre>
[root@lab8106 ceph]# ceph osd pool create testpool 6 6
pool 'testpool' created
</pre>

下面我们看一下默认创建完了后的PG分布情况：
<pre>
[root@lab8106 ceph]# ceph pg dump pgs|grep ^1|awk '{print $1,$2,$15}'
dumped pgs in format plain
1.1 0 [3,6,0]
1.0 0 [7,0,6]
1.3 0 [4,1,2]
1.2 0 [7,4,1]
1.5 0 [4,6,3]
1.4 0 [3,0,4]
</pre>

2) 写入对象

我们写入一些对象，因为我们关心的不仅是PG的变动，同样关心PG内对象有没有移动，所以需要准备一些测试数据，这个调用原生rados接口写最方便：
<pre>
# rados -p testpool bench 20 write --no-cleanup
</pre>


现在我们再来查询一次：
<pre>
[root@lab8106 ceph]# ceph pg dump pgs|grep ^1|awk '{print $1,$2,$15}'
dumped pgs in format plain
1.1 75 [3,6,0]
1.0 83 [7,0,6]
1.3 144 [4,1,2]
1.2 146 [7,4,1]
1.5 86 [4,6,3]
1.4 80 [3,0,4]
</pre>
可以看到写入了一些数据，其中第二列为这个PG当中的对象数目，第三列为PG所在的OSD。

## 2. 增加PG测试
我们来扩大PG再看看：
<pre>
[root@lab8106 ceph]# ceph osd pool set testpool pg_num 12
set pool 1 pg_num to 12
</pre>

再次查询：
<pre>
[root@lab8106 ceph]# ceph pg dump pgs|grep ^1|awk '{print $1,$2,$15}'
dumped pgs in format plain
1.1 37 [3,6,0]
1.9 38 [3,6,0]
1.0 41 [7,0,6]
1.8 42 [7,0,6]
1.3 48 [4,1,2]
1.b 48 [4,1,2]
1.7 48 [4,1,2]
1.2 48 [7,4,1]
1.6 49 [7,4,1]
1.a 49 [7,4,1]
1.5 86 [4,6,3]
1.4 80 [3,0,4]
</pre>

可以看到上面新加上的PG的分布还是基于老的分布组合，并没有出现新的OSD组合，因为我们当前的设置是```PGP```为6，那么三个OSD的组合个数就是6个，因为当前未12个PG，分布只能从6种组合里面挑选，所以会有重复的组合。

根据上面的分布情况，可以确定的是，增加PG操作会引起PG内部对象分裂，分裂的份数是根据新增PG组合重复情况来的，比如上面的情况：

* 1.1的对象分成了两份[3,6,0]

* 1.3的对象分成了三份[4,1,2]

* 1.4的对象没有拆分[3,0,4]

**结论：** 增加PG会引起PG内的对象分裂，也就是在OSD上创建新的PG目录，然后进行部分对象的move的操作

## 3. 增加PGP测试

我们将原来的PGP从6调整到12:
<pre>
[root@lab8106 ceph]# ceph osd pool set testpool pgp_num 12
[root@lab8106 ceph]# ceph pg dump pgs|grep ^1|awk '{print $1,$2,$15}'
dumped pgs in format plain
1.a 49 [1,2,6]
1.b 48 [1,6,2]
1.1 37 [3,6,0]
1.0 41 [7,0,6]
1.3 48 [4,1,2]
1.2 48 [7,4,1]
1.5 86 [4,6,3]
1.4 80 [3,0,4]
1.7 48 [1,6,0]
1.6 49 [3,6,7]
1.9 38 [1,4,2]
1.8 42 [1,2,3]
</pre>

从上面我们可以看到，PG里面的对象并没有发生变化，而PG所在的对应关系发生了变化。我们来看下与调整PGP前的对比：
<pre>
*1.1 37 [3,6,0]          1.1 37 [3,6,0]*
1.9 38 [3,6,0]          1.9 38 [1,4,2]
*1.0 41 [7,0,6]          1.0 41 [7,0,6]*
1.8 42 [7,0,6]          1.8 42 [1,2,3]
*1.3 48 [4,1,2]          1.3 48 [4,1,2]*
1.b 48 [4,1,2]          1.b 48 [1,6,2]
1.7 48 [4,1,2]          1.7 48 [1,6,0]
*1.2 48 [7,4,1]          1.2 48 [7,4,1]*
1.6 49 [7,4,1]          1.6 49 [3,6,7]
1.a 49 [7,4,1]          1.a 49 [1,2,6]
*1.5 86 [4,6,3]          1.5 86 [4,6,3]*
*1.4 80 [3,0,4]          1.4 80 [3,0,4]*
</pre>
可以看到，其中最原始的6个PG的分布并没有变化(标注了```*```号)，变化的是后增加的PG，也就是将重复的PG分布进行新分布，这里并不是随机完全打散，而是根据需要去进行重分布。

**结论：** 调整PGP不会引起PG内的对象的分裂，但会引起PG的分布的变动。


## 4. 关于PG的分裂算法
其实PG的分裂算法也相对简单，我们来看：
{% highlight string %}
/*
 * stable_mod func is used to control number of placement groups.
 * similar to straight-up modulo, but produces a stable mapping as b
 * increases over time.  b is the number of bins, and bmask is the
 * containing power of 2 minus 1.
 *
 * b <= bmask and bmask=(2**n)-1
 * e.g., b=12 -> bmask=15, b=123 -> bmask=127
 */
static inline int ceph_stable_mod(int x, int b, int bmask)
{
	if ((x & bmask) < b)
		return x & bmask;
	else
		return x & (bmask >> 1);
}

int pg_pool_t::calc_bits_of(int t)
{
	int b = 0;
	while (t > 0) {
		t = t >> 1;
		++b;
	}
	return b;
}

bool pg_t::is_split(unsigned old_pg_num, unsigned new_pg_num, set<pg_t> *children) const
{
	assert(m_seed < old_pg_num);
	if (new_pg_num <= old_pg_num)
		return false;
	
	bool split = false;
	if (true) {
		int old_bits = pg_pool_t::calc_bits_of(old_pg_num);
		int old_mask = (1 << old_bits) - 1;

		for (int n = 1; ; n++) {
			int next_bit = (n << (old_bits-1));     
			unsigned s = next_bit | m_seed;
	
			if (s < old_pg_num || s == m_seed)
				continue;
			if (s >= new_pg_num)
				break;

			if ((unsigned)ceph_stable_mod(s, old_pg_num, old_mask) == m_seed) {
				split = true;
				if (children)
					children->insert(pg_t(s, m_pool, m_preferred));
			}
		}
	}

	if (false) {
		// brute force
		int old_bits = pg_pool_t::calc_bits_of(old_pg_num);
		int old_mask = (1 << old_bits) - 1;

		for (unsigned x = old_pg_num; x < new_pg_num; ++x) {
			unsigned o = ceph_stable_mod(x, old_pg_num, old_mask);
			if (o == m_seed) {
				split = true;
				children->insert(pg_t(x, m_pool, m_preferred));
			}
		}
	}

	return split;
}

{% endhighlight %}

上面主要涉及到三个函数：

* 函数ceph_stable_mod(x, b, bmask):用于将x映射到(0,b)范围内，其中bmask是b的掩码。其与普通的取模运算相比，在b增加时，具有较低的数据迁移；而直接取模这种方式在扩容的时候迁移的数据量无法控制
{% highlight string %}
设: pg 数为 a,需要将 pg 数扩容至 b, a 和 b 的最小公倍数为 d，某个对象的key值为 q
 
由此可以得到如下两个方程式:
ca + e = q, e < a, q < d;
ub + v = q, v < b, q < d;
 
因为最小公倍数为 d, 如果 c != 0 && u != 0, 所以 ca != ub, 所以 e != v
 
当 c == u == 0的情况下, e == v,
所以需要迁移数据比例为: (d-a)/d
{% endhighlight %}
由此可以得到直接取模的方式无法控制迁移的数据量，例如 pg 数从 8 -> 12，直接取模的话需要迁移 (24 – 8) / 24 = 2/3 的数据。

下面给出一个示例图：

![ceph-peering-wq](https://ivanzz1001.github.io/records/assets/img/ceph/sca/ceph_stable_mod.jpg)


* 函数calc_bits_of(t)： 用于计算t需要用多少个bit位来表示

* 函数is_split()：用于计算当PG数由old扩容至new时，当前PG所分裂出的子PG。这里用了一个比较巧妙的方法，就是保持PG的低比特位不变，对高位进行扩容。下面我们来分析一下前面举的扩容例子：
{% highlight string %}
old_pg_num = 6, new_pg_num = 12，则old_bits =3, old_mask = 0b111

当n=1时：
   next_bit = 1 << (3-1) = 4 = 0b100       //注：这里需要用(old_bits-1)，因为old_bits位可能没有全部占满
   s = next_bit | m_seed = 0b100 | 0b001 = 0b101    //仍小于6，忽略

当n=2时：
   next_bit = 2 << (3-1) = 8 = 0b1000
   s = next_bit | m_seed = 0b1000 | 0b0001 = 0b1001 = 9   //大于6小于12，符合

当n=3时：
   next_bit = 3 << (3-1) = 12 = 0b1100
   s = next_bit | m_seed = 0b1100 | 0b0001 = 0b1101 = 13 //大于12，忽略
{% endhighlight %}

 

## 5. 总结
* PG是指定存储池存储对象的目录有多少个，PGP是存储池PG的OSD分布组合个数；

* PG的增加会引起PG内的数据进行分裂，分裂到相同的OSD上新生成的PG当中；

* PGP的增加会引起部分PG的分布进行变化，但是不会引起PG内对象的变动；




<br />
<br />

**[参看]**

1. [Ceph中PG和PGP的区别](https://blog.csdn.net/dengxiafubi/article/details/72957428)

2. [ceph 官网](https://ceph.io/)

3. [POOLS](https://ceph.readthedocs.io/en/latest/rados/operations/pools/#create-a-pool)

4. [ceph-pg哈希分析](https://blog.didiyun.com/index.php/2020/01/19/ceph-pg%E5%93%88%E5%B8%8C%E5%88%86%E6%9E%90/)


<br />
<br />
<br />

